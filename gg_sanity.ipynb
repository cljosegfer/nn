{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/josegfer/miniconda3/envs/lusiadas/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy.stats import multivariate_normal\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GG:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def torch(self, X: np.ndarray, p: float = 2):\n",
    "        X = torch.Tensor(X).to(DEVICE)\n",
    "        n = X.shape[0]\n",
    "        F = torch.cdist(X,X, p)**p\n",
    "        F.fill_diagonal_(float('inf'))\n",
    "\n",
    "        adj = torch.zeros((n,n), dtype=torch.bool).to(DEVICE)\n",
    "        for i in tqdm(range(n-1)):\n",
    "            A = F[i]+F[i+1:]\n",
    "            idx_min = torch.argmin(A, axis=1)\n",
    "            a = A[torch.arange(A.shape[0]), idx_min] - F[i, i+1:]\n",
    "            adj[i, i+1:] = torch.where(a > 0, 1, 0)\n",
    "        adj = adj + adj.T\n",
    "        return adj.cpu()\n",
    "    \n",
    "    def batch(self, X: np.ndarray, btsz: int, p: float = 2):\n",
    "        X = torch.Tensor(X).to(DEVICE)\n",
    "        n = X.shape[0]\n",
    "        adj = torch.zeros((n, n), dtype = torch.bool).to(DEVICE)\n",
    "        for i in tqdm(range(n)):\n",
    "            delta = torch.cdist(X[i:i+1, :], X, p)**p\n",
    "            delta[0, i] = float('inf')\n",
    "            val_min = torch.ones(n).to(DEVICE) * float('inf')\n",
    "            for b in range(0, n, btsz):\n",
    "                X_batch = X[b:b+btsz, :]\n",
    "                F_batch = torch.cdist(X_batch, X, p)**p\n",
    "                diag_idx = np.diag_indices(btsz)\n",
    "                diag_idx = (diag_idx[0], diag_idx[1] + b)\n",
    "                F_batch[diag_idx] = float('inf')\n",
    "                A_batch = delta[0, :btsz] + F_batch.T\n",
    "                val_min_batch, _ = torch.min(A_batch, axis = 1)\n",
    "                val_min, _ = torch.min(torch.stack((val_min, val_min_batch), dim = 1), dim = 1)\n",
    "                del X_batch, F_batch, A_batch, val_min_batch\n",
    "            a = val_min - delta[0, :]\n",
    "            adj[i, :] = torch.where(a > 0, 1, 0)\n",
    "            del val_min, a\n",
    "        adj = adj + adj.T\n",
    "        return adj.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate(X_train: np.ndarray, X_test: np.ndarray, btsz: int, p: float = 2)\n",
    "    X_train = torch.Tensor(X_train).to(DEVICE)\n",
    "    X_test = torch.Tensor(X_test).to(DEVICE)\n",
    "    n = X_train.shape[0]\n",
    "    N = X_test.shape[0]\n",
    "    adj = torch.zeros((N, n), dtype = torch.bool).to(DEVICE)\n",
    "    for i in tqdm(range(N)):\n",
    "        delta = torch.cdist(X[i:i+1, :], X, p)**p\n",
    "        delta[0, i] = float('inf')\n",
    "        val_min = torch.ones(n).to(DEVICE) * float('inf')\n",
    "        for b in range(0, n, btsz):\n",
    "            X_batch = X[b:b+btsz, :]\n",
    "            F_batch = torch.cdist(X_batch, X, p)**p\n",
    "            diag_idx = np.diag_indices(btsz)\n",
    "            diag_idx = (diag_idx[0], diag_idx[1] + b)\n",
    "            F_batch[diag_idx] = float('inf')\n",
    "            A_batch = delta[0, :btsz] + F_batch.T\n",
    "            val_min_batch, _ = torch.min(A_batch, axis = 1)\n",
    "            val_min, _ = torch.min(torch.stack((val_min, val_min_batch), dim = 1), dim = 1)\n",
    "            del X_batch, F_batch, A_batch, val_min_batch\n",
    "        a = val_min - delta[0, :]\n",
    "        adj[i, :] = torch.where(a > 0, 1, 0)\n",
    "        del val_min, a\n",
    "    adj = adj + adj.T\n",
    "    return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 5000\n",
    "btsz = 1000\n",
    "X = multivariate_normal.rvs(cov = np.eye(16), size = N)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4999/4999 [00:02<00:00, 2477.63it/s]\n"
     ]
    }
   ],
   "source": [
    "ggclass = GG()\n",
    "adjt = ggclass.torch(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:14<00:00, 344.27it/s]\n"
     ]
    }
   ],
   "source": [
    "adjb = ggclass.batch(X, btsz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False,  True]), array([ 2310978, 22689022]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(adjt.cpu().numpy() == adjb.cpu().numpy(), return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4999/4999 [00:02<00:00, 2458.93it/s]\n",
      "  2%|▏         | 93/5000 [00:16<14:53,  5.49it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m ggclass \u001b[39m=\u001b[39m GG()\n\u001b[1;32m      2\u001b[0m adjt \u001b[39m=\u001b[39m ggclass\u001b[39m.\u001b[39mtorch(X, p \u001b[39m=\u001b[39m \u001b[39m16\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m adjb \u001b[39m=\u001b[39m ggclass\u001b[39m.\u001b[39;49mbatch(X, btsz, p \u001b[39m=\u001b[39;49m \u001b[39m16\u001b[39;49m)\n\u001b[1;32m      4\u001b[0m np\u001b[39m.\u001b[39munique(adjt\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy() \u001b[39m==\u001b[39m adjb\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy(), return_counts \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[5], line 33\u001b[0m, in \u001b[0;36mGG.batch\u001b[0;34m(self, X, btsz, p)\u001b[0m\n\u001b[1;32m     31\u001b[0m diag_idx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdiag_indices(btsz)\n\u001b[1;32m     32\u001b[0m diag_idx \u001b[39m=\u001b[39m (diag_idx[\u001b[39m0\u001b[39m], diag_idx[\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m b)\n\u001b[0;32m---> 33\u001b[0m F_batch[diag_idx] \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39m'\u001b[39m\u001b[39minf\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     34\u001b[0m A_batch \u001b[39m=\u001b[39m delta[\u001b[39m0\u001b[39m, :btsz] \u001b[39m+\u001b[39m F_batch\u001b[39m.\u001b[39mT\n\u001b[1;32m     35\u001b[0m val_min_batch, _ \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmin(A_batch, axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ggclass = GG()\n",
    "adjt = ggclass.torch(X, p = 16)\n",
    "adjb = ggclass.batch(X, btsz, p = 16)\n",
    "np.unique(adjt.cpu().numpy() == adjb.cpu().numpy(), return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.Tensor(X).to(DEVICE)\n",
    "n = X.shape[0]\n",
    "adj = torch.zeros((n, n), dtype = torch.bool).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(n)):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 500])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta = torch.cdist(X[i:i+1, :], X)**2\n",
    "val_min = torch.ones(n).to(DEVICE) * 1e9\n",
    "delta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(0, n, btsz):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 500])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch = X[b:b+btsz, :]\n",
    "F_batch = torch.cdist(X_batch, X)**2\n",
    "F_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "        34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "        51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
       "        68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
       "        85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "        34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "        51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
       "        68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
       "        85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diag_idx = np.diag_indices(btsz)\n",
    "diag_idx = (diag_idx[0], diag_idx[1] + b)\n",
    "diag_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    inf, 44.4403, 35.6596,  ..., 30.7452, 53.4618, 51.7180],\n",
       "        [44.4403,     inf, 23.8903,  ..., 21.2678, 51.6006, 48.1585],\n",
       "        [35.6596, 23.8903,     inf,  ..., 21.4548, 49.9805, 24.7000],\n",
       "        ...,\n",
       "        [59.0344, 16.4907, 22.4236,  ..., 38.8746, 69.6844, 51.4538],\n",
       "        [72.1047, 39.4661, 55.4588,  ..., 40.0942, 49.2782, 70.8818],\n",
       "        [46.5412, 37.9725, 35.3928,  ..., 47.0189, 61.4506, 35.0358]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_batch[diag_idx] = float('inf')\n",
    "F_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 100])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_batch = delta[0, :btsz].T + F_batch.T\n",
    "A_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    X_batch = X[b:b+btsz, :]\n",
    "    F_batch = torch.cdist(X_batch, X)**2\n",
    "    diag_idx = np.diag_indices(btsz)\n",
    "    diag_idx = (diag_idx[0], diag_idx[1] + b)\n",
    "    F_batch[diag_idx] = np.inf\n",
    "    A_batch = delta[0, :btsz] + F_batch.T\n",
    "    val_min_batch, _ = torch.min(A_batch, axis = 1)\n",
    "    val_min, _ = torch.min(torch.stack((val_min, val_min_batch), dim = 1), dim = 1)\n",
    "    del X_batch, F_batch, A_batch, val_min_batch\n",
    "a = val_min - delta[0, :]\n",
    "adj[i, :] = torch.where(a > 0, 1, 0)\n",
    "del val_min, a\n",
    "adj = adj + adj.T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lusiadas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
