{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/josegfer/miniconda3/envs/lusiadas/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GG:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def torch(self, X: np.ndarray, p: float = 2):\n",
    "        X = torch.Tensor(X).to(DEVICE)\n",
    "        n = X.shape[0]\n",
    "        F = torch.cdist(X,X, p)**p\n",
    "        F.fill_diagonal_(float('inf'))\n",
    "\n",
    "        adj = torch.zeros((n,n), dtype=torch.bool).to(DEVICE)\n",
    "        for i in tqdm(range(n-1)):\n",
    "            A = F[i]+F[i+1:]\n",
    "            idx_min = torch.argmin(A, axis=1)\n",
    "            a = A[torch.arange(A.shape[0]), idx_min] - F[i, i+1:]\n",
    "            adj[i, i+1:] = torch.where(a > 0, 1, 0)\n",
    "        adj = adj + adj.T\n",
    "        return adj.cpu()\n",
    "    \n",
    "    def batch(self, X: np.ndarray, btsz: int, p: float = 2):\n",
    "        X = torch.Tensor(X).to(DEVICE)\n",
    "        n = X.shape[0]\n",
    "        adj = torch.zeros((n, n), dtype = torch.bool).to(DEVICE)\n",
    "        for i in tqdm(range(n)):\n",
    "            delta = torch.cdist(X[i:i+1, :], X, p)**p\n",
    "            delta[0, i] = float('inf')\n",
    "            val_min = torch.ones(n).to(DEVICE) * float('inf')\n",
    "            for b in range(0, n, btsz):\n",
    "                X_batch = X[b:b+btsz, :]\n",
    "                F_batch = torch.cdist(X_batch, X, p)**p\n",
    "                diag_idx = np.diag_indices(btsz)\n",
    "                diag_idx = (diag_idx[0], diag_idx[1] + b)\n",
    "                F_batch[diag_idx] = float('inf')\n",
    "                A_batch = delta[0, :btsz] + F_batch.T\n",
    "                val_min_batch, _ = torch.min(A_batch, axis = 1)\n",
    "                val_min, _ = torch.min(torch.stack((val_min, val_min_batch), dim = 1), dim = 1)\n",
    "                del X_batch, F_batch, A_batch, val_min_batch\n",
    "            a = val_min - delta[0, :]\n",
    "            adj[i, :] = torch.where(a > 0, 1, 0)\n",
    "            del val_min, a\n",
    "        adj = adj + adj.T\n",
    "        return adj.cpu()\n",
    "    \n",
    "    def separate(self, X_train: np.ndarray, X_test: np.ndarray, btsz: int, p: float = 2):\n",
    "        X_train = torch.Tensor(X_train).to(DEVICE)\n",
    "        X_test = torch.Tensor(X_test).to(DEVICE)\n",
    "        n = X_train.shape[0]\n",
    "        N = X_test.shape[0]\n",
    "        adj = torch.zeros((N, n), dtype = torch.bool).to(DEVICE)\n",
    "        delta = torch.cdist(X_test, X_train, p)**p\n",
    "        for i in tqdm(range(N)):\n",
    "            # delta = torch.cdist(X_test[i:i+1, :], X_train, p)**p\n",
    "            val_min = torch.ones(n).to(DEVICE) * float('inf')\n",
    "            for b in range(0, n, btsz):\n",
    "                X_batch = X_train[b:b+btsz, :]\n",
    "                F_batch = torch.cdist(X_batch, X_train, p)**p\n",
    "                A_batch = delta[i, :btsz] + F_batch.T\n",
    "                val_min_batch, _ = torch.min(A_batch, axis = 1)\n",
    "                val_min, _ = torch.min(torch.stack((val_min, val_min_batch), dim = 1), dim = 1)\n",
    "                del X_batch, F_batch, A_batch, val_min_batch\n",
    "            a = val_min - delta[i, :]\n",
    "            adj[i, :] = torch.where(a > 0, 1, 0)\n",
    "            del val_min, a\n",
    "        return adj.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_train = torch.load('data/H_train.pt')\n",
    "H_test = torch.load('data/H_test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ggclass = GG()\n",
    "# # adjb = ggclass.batch(H_train, len(H_train) // 4, p = 64)\n",
    "# adjt = ggclass.torch(H_train[25000:, :], p = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vizinhos = torch.sum(adjt, axis = 0)\n",
    "# torch.mean(vizinhos.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(adjt, 'data/gg_train_1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 248/10000 [2:16:34<89:30:32, 33.04s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m ggclass \u001b[39m=\u001b[39m GG()\n\u001b[0;32m----> 2\u001b[0m adjs \u001b[39m=\u001b[39m ggclass\u001b[39m.\u001b[39;49mseparate(H_train, H_test, \u001b[39mlen\u001b[39;49m(H_train) \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m \u001b[39m4\u001b[39;49m, p \u001b[39m=\u001b[39;49m \u001b[39m64\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[3], line 53\u001b[0m, in \u001b[0;36mGG.separate\u001b[0;34m(self, X_train, X_test, btsz, p)\u001b[0m\n\u001b[1;32m     50\u001b[0m delta \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcdist(X_test, X_train, p)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mp\n\u001b[1;32m     51\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(N)):\n\u001b[1;32m     52\u001b[0m     \u001b[39m# delta = torch.cdist(X_test[i:i+1, :], X_train, p)**p\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m     val_min \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mones(n)\u001b[39m.\u001b[39;49mto(DEVICE) \u001b[39m*\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39m'\u001b[39m\u001b[39minf\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     54\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, n, btsz):\n\u001b[1;32m     55\u001b[0m         X_batch \u001b[39m=\u001b[39m X_train[b:b\u001b[39m+\u001b[39mbtsz, :]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ggclass = GG()\n",
    "adjs = ggclass.separate(H_train, H_test, len(H_train) // 4, p = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(adjs, 'data/gg_test.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lusiadas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
